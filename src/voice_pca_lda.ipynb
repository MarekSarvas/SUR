{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikrlib import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import imageio\n",
    "import sys\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# paths to data directories\n",
    "TRAIN_TARGET = '../data/target_train/'\n",
    "TRAIN_NTARGET = '../data/non_target_train/'\n",
    "TEST_TARGET = '../data/target_dev/'\n",
    "TEST_NTARGET = '../data/non_target_dev/'\n",
    "THRESHOLD = 100000 # the evaluation treshold for the test data score\n",
    "\n",
    "# load target and non target voice data\n",
    "train_t = list(wav16khz2mfcc(TRAIN_TARGET).values())\n",
    "train_n = list(wav16khz2mfcc(TRAIN_NTARGET).values())\n",
    "\n",
    "\n",
    "# convert to numpy arrays\n",
    "train_t = np.vstack(train_t)\n",
    "train_n = np.vstack(train_n)\n",
    "dim = train_t.shape[1]\n",
    "\n",
    "# standardise the data for PCA, in LDA this makes no difference\n",
    "train_mean = np.mean(np.vstack((train_t, train_n)), axis=0) \n",
    "train_std = np.std(np.vstack((train_t, train_n)), axis=0)\n",
    "train_t -= train_mean\n",
    "train_t /= train_std\n",
    "train_n -= train_mean\n",
    "train_n /= train_std\n",
    "\n",
    "cov_tot = np.cov(np.vstack([train_t, train_n]).T, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "d_pca, e_pca = scipy.linalg.eigh(cov_tot, eigvals=(dim-1, dim-1))\n",
    "# one dimensional data\n",
    "x1_pca = train_t.dot(e_pca)\n",
    "x2_pca = train_n.dot(e_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result, not great\n",
    "plt.figure()\n",
    "junk = plt.hist(x1_pca, 40, histtype='step', color='b')\n",
    "junk = plt.hist(x2_pca, 40, histtype='step', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "n_x1 = len(train_t)\n",
    "n_x2 = len(train_n)\n",
    "\n",
    "# within and across class, cov_tot = ac+wc\n",
    "cov_wc = (n_x1*np.cov(train_t.T, bias=True) + n_x2*np.cov(train_n.T, bias=True)) / (n_x1 + n_x2)\n",
    "cov_ac = cov_tot - cov_wc\n",
    "d_lda, e_lda = scipy.linalg.eigh(cov_ac, cov_wc, eigvals=(dim-1, dim-1)) \n",
    "\n",
    "# one dimensional data\n",
    "x1_lda = train_t.dot(e_lda)\n",
    "x2_lda = train_n.dot(e_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result, also not great\n",
    "plt.figure()\n",
    "junk = plt.hist(x1_lda, 40, histtype='step', color='b')\n",
    "junk = plt.hist(x2_lda, 40, histtype='step', color='r')\n",
    "plt.show()\n"
   ]
  }
 ]
}