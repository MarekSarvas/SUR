{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "from ikrlib import *\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data directories\n",
    "TRAIN_TARGET = '../data/target_train/'\n",
    "TRAIN_NTARGET = '../data/non_target_train/'\n",
    "TEST_TARGET = '../data/target_dev/'\n",
    "TEST_NTARGET = '../data/non_target_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load target and non target voice data\n",
    "train_t = list(wav16khz2mfcc(TRAIN_TARGET).values()) # target train data\n",
    "train_n = list(wav16khz2mfcc(TRAIN_NTARGET).values()) # non-target train data\n",
    "\n",
    "print('TEST DATA')\n",
    "test_t = wav16khz2mfcc(TEST_TARGET) # target test data\n",
    "test_n = wav16khz2mfcc(TEST_NTARGET) # non-target test data\n",
    "\n",
    "print(train_t[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters for us to play with....\n",
    "MEAN_SEGMENT_LEN = 20\n",
    "INITIAL_CUTOFF = 190\n",
    "MEAN_MULTIPLIER = 1\n",
    "DEFAULT_MEAN = 40.0\n",
    "\n",
    "# this function cuts up the array to chunks and lets us process these\n",
    "def divide_chunks(l, n):\n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    "        \n",
    "def remove_silence(record):\n",
    "    # First cut off the first 190 frames of the recording\n",
    "    record = record[INITIAL_CUTOFF:]\n",
    "    # calculate the mean energy in order to remove silence\n",
    "    mean_energy = np.mean(record[:][:,0])\n",
    "    #print(mean_energy)\n",
    "\n",
    "    \n",
    "    if mean_energy > DEFAULT_MEAN: mean_energy = DEFAULT_MEAN\n",
    "    \n",
    "    # now split the arrays into segments of length MEAN_SEGMENT_LEN\n",
    "    # and compare the mean of these chunks to the overall mean\n",
    "    new = []\n",
    "    for seg in divide_chunks(record, MEAN_SEGMENT_LEN):\n",
    "        print(np.mean(seg[:][:,0]), mean_energy, mean_energy*MEAN_MULTIPLIER)\n",
    "        \n",
    "        if np.mean(seg[:][:,0]) > mean_energy * MEAN_MULTIPLIER:\n",
    "            new.append(seg)\n",
    "            \n",
    "    return np.vstack(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the silence from the training data\n",
    "target = []\n",
    "for rec in train_t:\n",
    "    target.append(remove_silence(rec))\n",
    "\n",
    "ntarget = []\n",
    "for rec in train_n:\n",
    "    ntarget.append(remove_silence(rec))\n",
    "    \n",
    "test_target = []\n",
    "for rec in list(test_t.values()):\n",
    "    test_target.append(remove_silence(rec))\n",
    "\n",
    "test_ntarget = []\n",
    "for rec in list(test_n.values()):\n",
    "    test_ntarget.append(remove_silence(rec))\n",
    "\n",
    "X_train_t = np.vstack(target)\n",
    "X_train_n = np.vstack(ntarget)\n",
    "X_test_t = np.vstack(test_target)\n",
    "X_test_n = np.vstack(test_ntarget)\n",
    "\n",
    "# After cutting the silence\n",
    "plt.figure()\n",
    "plt.plot(X_train_t[:1000][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# First cut off the first 190 frames of each recording\n",
    "target = []\n",
    "for rec in train_t:\n",
    "    target.append(rec[INITIAL_CUTOFF:])\n",
    "\n",
    "ntarget = []\n",
    "for rec in train_n:\n",
    "    ntarget.append(rec[INITIAL_CUTOFF:])\n",
    "    \n",
    "X_train_t = np.vstack(target)\n",
    "X_train_n = np.vstack(ntarget)\n",
    "\n",
    "# Before cutting the silence..\n",
    "plt.figure()\n",
    "plt.plot(X_train_t[:1000][:,0])\n",
    "\n",
    "# calculate the mean energy in order to remove silence\n",
    "mean_energy = np.mean(np.hstack((X_train_t[:][:,0], X_train_n[:][:,0])))\n",
    "print(mean_energy)\n",
    "\n",
    "\n",
    "# now split the arrays into segments of length 10 and compare the mean of these chunks to the overall mean\n",
    "target = []\n",
    "for seg in divide_chunks(X_train_t, MEAN_SEGMENT_LEN):\n",
    "    if np.mean(seg[:][:,0]) > mean_energy*MEAN_MULTIPLIER:\n",
    "        target.append(seg)\n",
    "ntarget = []\n",
    "for seg in divide_chunks(X_train_n, MEAN_SEGMENT_LEN):\n",
    "    if np.mean(seg[:][:,0]) > mean_energy*MEAN_MULTIPLIER:\n",
    "        ntarget.append(seg)\n",
    "        \n",
    "X_train_t = np.vstack(target)\n",
    "X_train_n = np.vstack(ntarget)\n",
    "\n",
    "# After cutting the silence\n",
    "plt.figure()\n",
    "plt.plot(X_train_t[:1000][:,0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_LEN = 13\n",
    "STEP = 3\n",
    "\n",
    "# this function creates \"pictures\" from our features by grouping them up\n",
    "def create_frame_batches(data):\n",
    "    grouped = []\n",
    "    for i in range(0, data.shape[0] - BATCH_LEN, STEP):\n",
    "        group = []\n",
    "        for j in range(BATCH_LEN):\n",
    "            group.append(data[i+j])\n",
    "        grouped.append(np.vstack(group).flatten().reshape(BATCH_LEN, 13, 1))\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 13x13 batches from the data\n",
    "X_train_t = np.array(create_frame_batches(X_train_t))\n",
    "X_train_n = np.array(create_frame_batches(X_train_n))\n",
    "X_test_t = np.array(create_frame_batches(X_test_t))\n",
    "X_test_n = np.array(create_frame_batches(X_test_n))\n",
    "\n",
    "# Get all the data to one place\n",
    "X_train = np.vstack((X_train_t, X_train_n))\n",
    "y_train = np.hstack((np.zeros(X_train_t.shape[0]), np.ones(X_train_n.shape[0])))\n",
    "\n",
    "X_test = np.vstack((X_test_t, X_test_n))\n",
    "y_test = np.hstack((np.zeros(X_test_t.shape[0]), np.ones(X_test_n.shape[0])))\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our model\n",
    "model = Sequential()\n",
    "model.add(Flatten(data_format='channels_last'))\n",
    "model.add(Dense(13 * BATCH_LEN, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train_hot, batch_size = 32, epochs=40, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution\n",
    "model = Sequential()\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
