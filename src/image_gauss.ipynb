{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikrlib import *\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import imageio\n",
    "from sys import exit\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# paths to data directories\n",
    "TRAIN_TARGET = '../data/target_train/'\n",
    "TRAIN_NTARGET = '../data/non_target_train/'\n",
    "TEST_TARGET = '../data/target_dev/'\n",
    "TEST_NTARGET = '../data/non_target_dev/'\n",
    "THRESHOLD = 100000 # the evaluation treshold for the test data score\n",
    "\n",
    "# first, load target and non-target training and test data and convert each image\n",
    "# to a 1d array\n",
    "train_target = png2fea(TRAIN_TARGET) # target training data\n",
    "train_ntarget = png2fea(TRAIN_NTARGET) # non-target training data\n",
    "test_target = list(png2fea(TEST_TARGET).items()) # target test data\n",
    "test_ntarget = list(png2fea(TEST_NTARGET).items()) # non-target test data\n",
    "\n",
    "# convert the grayscale images to 1d arrays\n",
    "x1 = []\n",
    "x2 = []\n",
    "#image = gaussian_filter(list(train_target.values())[0], 1)\n",
    "#imageio.imwrite('hello.png', image)\n",
    "#for im in train_target.values(): x1.append(gaussian_filter(im, 1).flatten())\n",
    "#for im in train_ntarget.values(): x2.append(gaussian_filter(im, 1).flatten())\n",
    "for im in train_target.values(): x1.append(im.flatten())\n",
    "for im in train_ntarget.values(): x2.append(im.flatten())\n",
    "\n",
    "# convert data to numpy arrays\n",
    "x1 = np.array(x1) # target\n",
    "x2 = np.array(x2) # non-target\n",
    "dim = x1.shape[1]\n",
    "\n",
    "# standardise the data\n",
    "train_mean = np.mean(np.vstack((x1, x2)), axis=0) \n",
    "train_std = np.std(np.vstack((x1, x2)), axis=0)\n",
    "x1 -= train_mean\n",
    "x1 /= train_std\n",
    "x2 -= train_mean\n",
    "x2 /= train_std\n",
    "cov_tot = np.cov(np.vstack([x1, x2]).T, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - reduce the dimensionality to 150 dimensions, otherwise the LDA won't work because MALO DAT...\n",
    "d_pca, e_pca = scipy.linalg.eigh(cov_tot, eigvals=(dim-150, dim-1))\n",
    "x1_pca = x1.dot(e_pca)\n",
    "x2_pca = x2.dot(e_pca)\n",
    "\n",
    "# plot the pca result, nothing interesting...\n",
    "#plt.plot(x1_pca[:,1], x1_pca[:,0], 'b.', ms=1)\n",
    "#plt.plot(x2_pca[:,1], x2_pca[:,0], 'r.', ms=1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the LDA on the reduced data space\n",
    "cov_tot_pca = np.cov(np.vstack([x1_pca, x2_pca]).T, bias=True)\n",
    "dim_pca = x1_pca.shape[1]\n",
    "\n",
    "n_x1 = len(x1)\n",
    "n_x2 = len(x2)\n",
    "cov_wc = (n_x1*np.cov(x1_pca.T, bias=True) + n_x2*np.cov(x2_pca.T, bias=True)) / (n_x1 + n_x2)\n",
    "cov_ac = cov_tot_pca - cov_wc\n",
    "d_lda, e_lda = scipy.linalg.eigh(cov_ac, cov_wc, eigvals=(dim_pca-1, dim_pca-1))\n",
    "\n",
    "# now we've got our one dimensional data\n",
    "x1_lda = x1_pca.dot(e_lda)\n",
    "x2_lda = x2_pca.dot(e_lda)\n",
    "\n",
    "# ... and plot the lda result.. beautiful...\n",
    "plt.figure()\n",
    "junk = plt.hist(x1_lda, 40, histtype='step', color='b')\n",
    "junk = plt.hist(x2_lda, 40, histtype='step', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gaussian distributions for our classes and evalueate the test data\n",
    "apriori = 0.5\n",
    "mean_x1, cov_x1 = train_gauss(x1_lda)\n",
    "mean_x2, cov_x2 = train_gauss(x2_lda)\n",
    "\n",
    "# plot the gaussians... awesome..\n",
    "plt.figure()\n",
    "gauss_x1 = np.linspace(mean_x1 - 10*cov_x1, mean_x1 + 10*cov_x1, 100)\n",
    "gauss_x2 = np.linspace(mean_x2 - 10*cov_x2, mean_x2 + 10*cov_x2, 100)\n",
    "plt.plot(gauss_x1, stats.norm.pdf(gauss_x1, mean_x1, cov_x1))\n",
    "plt.plot(gauss_x2, stats.norm.pdf(gauss_x2, mean_x2, cov_x2))\n",
    "plt.show()\n",
    "\n",
    "total = 0\n",
    "ok = 0\n",
    "print('======Target test data evaluation======')\n",
    "for filename, data in test_target:\n",
    "    total += 1\n",
    "    # standardise the data\n",
    "    data = data.flatten()\n",
    "    #data = gaussian_filter(data, 1).flatten()\n",
    "    data -= train_mean\n",
    "    data /= train_std\n",
    "    \n",
    "    data = (data.dot(e_pca)).dot(e_lda) # transform the test data\n",
    "    ll_target = logpdf_gauss(data, mean_x1, np.atleast_2d(cov_x1))\n",
    "    ll_ntarget = logpdf_gauss(data, mean_x2, np.atleast_2d(cov_x2))\n",
    "\n",
    "    # indicates whether the data point was correctly classified\n",
    "    if int(sum(ll_target) - sum(ll_ntarget)) > THRESHOLD:\n",
    "        ok += 1\n",
    "        correct = True\n",
    "    else: correct = False\n",
    "    \n",
    "    print(correct, int(sum(ll_target) - sum(ll_ntarget)), filename)\n",
    "\n",
    "print((ok/total) * 100)\n",
    "\n",
    "print('')\n",
    "print('======Non-target test data evaluation======')\n",
    "total = 0\n",
    "ok = 0\n",
    "for filename, data in test_ntarget:\n",
    "    total += 1\n",
    "    # standardise the data\n",
    "    data = data.flatten()\n",
    "    #data = gaussian_filter(data, 1).flatten()\n",
    "    data -= train_mean\n",
    "    data /= train_std\n",
    "    \n",
    "    data = (data.dot(e_pca)).dot(e_lda)\n",
    "    ll_target = logpdf_gauss(data, mean_x1, np.atleast_2d(cov_x1))\n",
    "    ll_ntarget = logpdf_gauss(data, mean_x2, np.atleast_2d(cov_x2))\n",
    "    \n",
    "    # indicates whether the data point was correctly classified\n",
    "    if int(sum(ll_target) - sum(ll_ntarget)) < THRESHOLD:\n",
    "        ok += 1\n",
    "        correct = True\n",
    "    else: correct = False\n",
    "          \n",
    "    print(correct, int(sum(ll_target) - sum(ll_ntarget)), filename)\n",
    "\n",
    "print((ok/total) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
